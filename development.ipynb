{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import mlflow\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_percentage_error   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "\n",
    "    def __init__(self, data:pd.DataFrame, target_column:str, test_size:float=0.2, datetime_column:str=None):\n",
    "\n",
    "        if datetime_column== None:\n",
    "            data = data.reset_index(drop=True).reset_index()\n",
    "            datetime_column= 'index'\n",
    "        self.datetime_column = datetime_column\n",
    "        self.target_column = target_column\n",
    "\n",
    "        # Dropping nan values\n",
    "        data= data.dropna()\n",
    "\n",
    "        # Raising exception if data is not present\n",
    "        if data.shape[0] == 0:\n",
    "            raise NoDataPresentException\n",
    "        \n",
    "        # sorting values accoriding to datetime\n",
    "        data = data.sort_values(by = self.datetime_column, ascending = True)\n",
    "        self.data_test = data.tail(int(test_size*len(data)))\n",
    "\n",
    "        data = data.drop(self.data_test.index)\n",
    "        self.y = data[target_column]\n",
    "        self.X = data.drop(target_column, axis = 1)\n",
    "        self.X_test = self.data_test.drop(target_column, axis = 1)\n",
    "        self.y_test = self.data_test[target_column]\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate(test:pd.Series, preds: pd.Series, process:str)->tuple:\n",
    "        score=r2_score(test,preds)\n",
    "        mse = mean_squared_error(test,preds)\n",
    "        rmse = np.sqrt(mean_squared_error(test,preds))\n",
    "        mape = mean_absolute_percentage_error(test,preds)\n",
    "        mae= mean_absolute_error(test, preds)\n",
    "\n",
    "        print('For {}'.format(process))\n",
    "        print('r2_score: {}\\nmse:{}\\nrmse:{}\\nmape:{}\\nmae:{}'.format(score, mse, rmse, mape, mae))\n",
    "\n",
    "        return (score, mse, rmse, mape, mae)\n",
    "\n",
    "\n",
    "    def LinearRegression(self, train_size:int=20, random_state:int=0, **kwargs)->dict:\n",
    "        session = mlflow.start_run()\n",
    "        \n",
    "        with session : \n",
    "            \n",
    "            data_for_graphs= {}\n",
    "\n",
    "            self.train_size = train_size       \n",
    "            self.random_state = random_state\n",
    "            \n",
    "            self.x_train, self.x_valid, self.y_train, self.y_valid = train_test_split(self.X, self.y, train_size = train_size, random_state = random_state)\n",
    "            \n",
    "            self.x_valid1 = self.x_valid.drop(self.datetime_column, axis = 1)\n",
    "            self.x_train1 = self.x_train.drop(self.datetime_column, axis = 1) \n",
    "            \n",
    "            ## Building a model\n",
    "            mlflow.log_param(\"Model Type\", 'LinearRegressor' )\n",
    "            self.model =  LinearRegression(**kwargs)\n",
    "            self.model.fit(self.x_train1,self.y_train)\n",
    "            \n",
    "            ## On Training Data:\n",
    "            y_pred_train = self.model.predict(self.x_train1)\n",
    "            (self.train_score, self.train_mse, self.train_rmse, self.train_mape, self.train_mae) = Regression.evaluate(self.y_train, y_pred_train, 'Train')\n",
    "            data_for_graph['train'] = pd.DataFrame({'Actual': self.y_train, 'Predictions': y_pred_train, 'Date_time': self.x_train[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "            ## On Validation Data:\n",
    "            y_pred_valid = self.model.predict(self.x_valid1)\n",
    "            (self.valid_score, self.valid_mse, self.valid_rmse, self.valid_mape, self.valid_mae) = Regression.evaluate(self.y_valid, y_pred_valid, 'Validation')\n",
    "            data_for_graph['validation'] = pd.DataFrame({'Actual': self.y_valid, 'Predictions': y_pred_valid, 'Date_time': self.x_valid[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "            ## On Test data: \n",
    "            y_pred_test = self.model.predict(self.X_test.drop(self.datetime_column, axis = 1))\n",
    "            (self.test_score, self.test_mse, self.test_rmse, self.test_mape, self.test_mae) = Regression.evaluate(self.y_test, y_pred_test, 'OOT')\n",
    "            self.result_OOT = pd.DataFrame({'Actual': self.y_test, 'Predictions': y_pred_test, 'Date_time': self.X_test[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "            \n",
    "\n",
    "            # Log parameters and metrics to MLflow\n",
    "            mlflow.log_param(\"train_size\", train_size)\n",
    "            mlflow.log_param(\"random_state\", random_state)\n",
    "            mlflow.log_param(\"model_type\", \"Linear Regressor\")\n",
    "            mlflow.log_params(kwargs)\n",
    "\n",
    "            mlflow.log_metric(\"r2_score_train\", self.train_score)\n",
    "            mlflow.log_metric(\"mse_train\", self.train_mse)\n",
    "            mlflow.log_metric(\"rmse_train\", self.train_rmse)\n",
    "            mlflow.log_metric(\"mape_train\", self.train_mape)\n",
    "\n",
    "            mlflow.log_metric(\"r2_score_test\", self.test_score)\n",
    "            mlflow.log_metric(\"mse_test\", self.test_mse)\n",
    "            mlflow.log_metric(\"rmse_test\", self.test_rmse)\n",
    "            mlflow.log_metric(\"mape_test\", self.test_mape)\n",
    "\n",
    "            mlflow.log_metric(\"r2_score_OOT\", self.OOT_score)\n",
    "            mlflow.log_metric(\"mse_OOT\", self.OOT_mse)\n",
    "            mlflow.log_metric(\"rmse_OOT\", self.OOT_rmse)\n",
    "            mlflow.log_metric(\"mape_OOT\", self.OOT_mape)\n",
    "\n",
    "            mlflow.sklearn.log_model(self.model, \"model\")\n",
    "            \n",
    "            return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>...</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>WELL</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1518.2800</td>\n",
       "      <td>433906.7500</td>\n",
       "      <td>6460000.5</td>\n",
       "      <td>-1493.241821</td>\n",
       "      <td>15.506232</td>\n",
       "      <td>2.237042</td>\n",
       "      <td>0.950333</td>\n",
       "      <td>0.878615</td>\n",
       "      <td>2.072248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109706</td>\n",
       "      <td>0.275208</td>\n",
       "      <td>0.853690</td>\n",
       "      <td>88.968864</td>\n",
       "      <td>0.822429</td>\n",
       "      <td>15/9-23</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1518.4320</td>\n",
       "      <td>433906.7500</td>\n",
       "      <td>6460000.5</td>\n",
       "      <td>-1493.393799</td>\n",
       "      <td>18.524611</td>\n",
       "      <td>2.198390</td>\n",
       "      <td>0.946200</td>\n",
       "      <td>0.874237</td>\n",
       "      <td>2.049179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>0.543080</td>\n",
       "      <td>0.831179</td>\n",
       "      <td>92.287186</td>\n",
       "      <td>0.826374</td>\n",
       "      <td>15/9-23</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1518.5840</td>\n",
       "      <td>433906.7500</td>\n",
       "      <td>6460000.5</td>\n",
       "      <td>-1493.545776</td>\n",
       "      <td>18.855669</td>\n",
       "      <td>2.114124</td>\n",
       "      <td>0.929856</td>\n",
       "      <td>0.869858</td>\n",
       "      <td>2.038348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>0.610418</td>\n",
       "      <td>0.835320</td>\n",
       "      <td>95.605499</td>\n",
       "      <td>0.819632</td>\n",
       "      <td>15/9-23</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1518.7360</td>\n",
       "      <td>433906.7500</td>\n",
       "      <td>6460000.5</td>\n",
       "      <td>-1493.697754</td>\n",
       "      <td>19.163353</td>\n",
       "      <td>1.946680</td>\n",
       "      <td>0.927579</td>\n",
       "      <td>0.865479</td>\n",
       "      <td>2.020606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024972</td>\n",
       "      <td>0.538517</td>\n",
       "      <td>0.868298</td>\n",
       "      <td>98.923820</td>\n",
       "      <td>0.841034</td>\n",
       "      <td>15/9-23</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1518.8880</td>\n",
       "      <td>433906.7500</td>\n",
       "      <td>6460000.5</td>\n",
       "      <td>-1493.849609</td>\n",
       "      <td>18.489744</td>\n",
       "      <td>1.193619</td>\n",
       "      <td>0.849849</td>\n",
       "      <td>0.863804</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024527</td>\n",
       "      <td>0.359408</td>\n",
       "      <td>0.851085</td>\n",
       "      <td>102.242142</td>\n",
       "      <td>0.814464</td>\n",
       "      <td>15/9-23</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122392</th>\n",
       "      <td>122392</td>\n",
       "      <td>2973.2988</td>\n",
       "      <td>536096.0625</td>\n",
       "      <td>6793022.0</td>\n",
       "      <td>-2943.444580</td>\n",
       "      <td>8.276272</td>\n",
       "      <td>2.644125</td>\n",
       "      <td>2.820439</td>\n",
       "      <td>3.158570</td>\n",
       "      <td>2.464931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502458</td>\n",
       "      <td>5.594451</td>\n",
       "      <td>2.311106</td>\n",
       "      <td>24.306124</td>\n",
       "      <td>2.972307</td>\n",
       "      <td>35/9-7</td>\n",
       "      <td>BAAT GP.</td>\n",
       "      <td>Etive Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122393</th>\n",
       "      <td>122393</td>\n",
       "      <td>2973.4508</td>\n",
       "      <td>536096.0625</td>\n",
       "      <td>6793022.0</td>\n",
       "      <td>-2943.595947</td>\n",
       "      <td>8.267273</td>\n",
       "      <td>2.201899</td>\n",
       "      <td>3.020778</td>\n",
       "      <td>3.332977</td>\n",
       "      <td>2.470371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374753</td>\n",
       "      <td>4.898014</td>\n",
       "      <td>1.853418</td>\n",
       "      <td>22.201078</td>\n",
       "      <td>2.516858</td>\n",
       "      <td>35/9-7</td>\n",
       "      <td>BAAT GP.</td>\n",
       "      <td>Etive Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122394</th>\n",
       "      <td>122394</td>\n",
       "      <td>2973.6028</td>\n",
       "      <td>536096.0625</td>\n",
       "      <td>6793022.0</td>\n",
       "      <td>-2943.747559</td>\n",
       "      <td>8.250099</td>\n",
       "      <td>1.715108</td>\n",
       "      <td>2.795711</td>\n",
       "      <td>3.044179</td>\n",
       "      <td>2.472233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211487</td>\n",
       "      <td>3.569129</td>\n",
       "      <td>1.325961</td>\n",
       "      <td>20.096741</td>\n",
       "      <td>1.723662</td>\n",
       "      <td>35/9-7</td>\n",
       "      <td>BAAT GP.</td>\n",
       "      <td>Etive Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122395</th>\n",
       "      <td>122395</td>\n",
       "      <td>2973.7548</td>\n",
       "      <td>536096.0625</td>\n",
       "      <td>6793022.0</td>\n",
       "      <td>-2943.899170</td>\n",
       "      <td>8.695217</td>\n",
       "      <td>1.575916</td>\n",
       "      <td>2.658694</td>\n",
       "      <td>2.847681</td>\n",
       "      <td>2.518067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>0.342615</td>\n",
       "      <td>1.260347</td>\n",
       "      <td>17.992323</td>\n",
       "      <td>0.330439</td>\n",
       "      <td>35/9-7</td>\n",
       "      <td>BAAT GP.</td>\n",
       "      <td>Etive Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122396</th>\n",
       "      <td>122396</td>\n",
       "      <td>2973.9068</td>\n",
       "      <td>536096.0625</td>\n",
       "      <td>6793022.0</td>\n",
       "      <td>-2944.050537</td>\n",
       "      <td>8.691441</td>\n",
       "      <td>1.640254</td>\n",
       "      <td>2.802693</td>\n",
       "      <td>2.972499</td>\n",
       "      <td>2.510440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174232</td>\n",
       "      <td>0.342615</td>\n",
       "      <td>1.266063</td>\n",
       "      <td>15.889325</td>\n",
       "      <td>1.787634</td>\n",
       "      <td>35/9-7</td>\n",
       "      <td>BAAT GP.</td>\n",
       "      <td>Etive Fm.</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122397 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   DEPTH_MD        X_LOC      Y_LOC        Z_LOC       CALI  \\\n",
       "0                0  1518.2800  433906.7500  6460000.5 -1493.241821  15.506232   \n",
       "1                1  1518.4320  433906.7500  6460000.5 -1493.393799  18.524611   \n",
       "2                2  1518.5840  433906.7500  6460000.5 -1493.545776  18.855669   \n",
       "3                3  1518.7360  433906.7500  6460000.5 -1493.697754  19.163353   \n",
       "4                4  1518.8880  433906.7500  6460000.5 -1493.849609  18.489744   \n",
       "...            ...        ...          ...        ...          ...        ...   \n",
       "122392      122392  2973.2988  536096.0625  6793022.0 -2943.444580   8.276272   \n",
       "122393      122393  2973.4508  536096.0625  6793022.0 -2943.595947   8.267273   \n",
       "122394      122394  2973.6028  536096.0625  6793022.0 -2943.747559   8.250099   \n",
       "122395      122395  2973.7548  536096.0625  6793022.0 -2943.899170   8.695217   \n",
       "122396      122396  2973.9068  536096.0625  6793022.0 -2944.050537   8.691441   \n",
       "\n",
       "            RSHA      RMED      RDEP      RHOB  ...      DRHO  MUDWEIGHT  \\\n",
       "0       2.237042  0.950333  0.878615  2.072248  ...  0.109706   0.275208   \n",
       "1       2.198390  0.946200  0.874237  2.049179  ... -0.006418   0.543080   \n",
       "2       2.114124  0.929856  0.869858  2.038348  ...  0.022769   0.610418   \n",
       "3       1.946680  0.927579  0.865479  2.020606  ...  0.024972   0.538517   \n",
       "4       1.193619  0.849849  0.863804  2.130803  ...  0.024527   0.359408   \n",
       "...          ...       ...       ...       ...  ...       ...        ...   \n",
       "122392  2.644125  2.820439  3.158570  2.464931  ...  0.502458   5.594451   \n",
       "122393  2.201899  3.020778  3.332977  2.470371  ...  0.374753   4.898014   \n",
       "122394  1.715108  2.795711  3.044179  2.472233  ...  0.211487   3.569129   \n",
       "122395  1.575916  2.658694  2.847681  2.518067  ...  0.147950   0.342615   \n",
       "122396  1.640254  2.802693  2.972499  2.510440  ...  0.174232   0.342615   \n",
       "\n",
       "            RMIC        ROPA       RXO     WELL          GROUP  FORMATION  \\\n",
       "0       0.853690   88.968864  0.822429  15/9-23  HORDALAND GP.  Skade Fm.   \n",
       "1       0.831179   92.287186  0.826374  15/9-23  HORDALAND GP.  Skade Fm.   \n",
       "2       0.835320   95.605499  0.819632  15/9-23  HORDALAND GP.  Skade Fm.   \n",
       "3       0.868298   98.923820  0.841034  15/9-23  HORDALAND GP.  Skade Fm.   \n",
       "4       0.851085  102.242142  0.814464  15/9-23  HORDALAND GP.  Skade Fm.   \n",
       "...          ...         ...       ...      ...            ...        ...   \n",
       "122392  2.311106   24.306124  2.972307   35/9-7       BAAT GP.  Etive Fm.   \n",
       "122393  1.853418   22.201078  2.516858   35/9-7       BAAT GP.  Etive Fm.   \n",
       "122394  1.325961   20.096741  1.723662   35/9-7       BAAT GP.  Etive Fm.   \n",
       "122395  1.260347   17.992323  0.330439   35/9-7       BAAT GP.  Etive Fm.   \n",
       "122396  1.266063   15.889325  1.787634   35/9-7       BAAT GP.  Etive Fm.   \n",
       "\n",
       "        FORCE_2020_LITHOFACIES_LITHOLOGY  FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "0                                  65000                                3.0  \n",
       "1                                  65000                                3.0  \n",
       "2                                  65000                                3.0  \n",
       "3                                  65000                                3.0  \n",
       "4                                  65000                                3.0  \n",
       "...                                  ...                                ...  \n",
       "122392                             65000                                2.0  \n",
       "122393                             65000                                2.0  \n",
       "122394                             65000                                2.0  \n",
       "122395                             65000                                2.0  \n",
       "122396                             65000                                2.0  \n",
       "\n",
       "[122397 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= df.dtypes[(df.dtypes == 'category') | (df.dtypes == 'str') | (df.dtypes == 'object')].index\n",
    "df= df.drop(cols, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Regression(df, \u001b[39m'\u001b[39;49m\u001b[39mFORCE_2020_LITHOFACIES_LITHOLOGY\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mLinearRegression()\n",
      "Cell \u001b[1;32mIn[30], line 64\u001b[0m, in \u001b[0;36mRegression.LinearRegression\u001b[1;34m(self, train_size, random_state, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39m## On Training Data:\u001b[39;00m\n\u001b[0;32m     63\u001b[0m y_pred_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train1)\n\u001b[1;32m---> 64\u001b[0m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_score, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_mse, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_rmse, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_mape) \u001b[39m=\u001b[39m Regression\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, y_pred_train, \u001b[39m'\u001b[39;49m\u001b[39mTrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     65\u001b[0m data_for_graph[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mActual\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train, \u001b[39m'\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m'\u001b[39m: y_pred_train, \u001b[39m'\u001b[39m\u001b[39mDate_time\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatetime_column]})\u001b[39m.\u001b[39msort_values(by \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDate_time\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mreset_index(drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[39m## On Validation Data:\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[30], line 31\u001b[0m, in \u001b[0;36mRegression.evaluate\u001b[1;34m(test, preds, process)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(test:pd\u001b[39m.\u001b[39mSeries, preds: pd\u001b[39m.\u001b[39mSeries, process:\u001b[39mstr\u001b[39m)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m\u001b[39mtuple\u001b[39m:\n\u001b[1;32m---> 31\u001b[0m     score\u001b[39m=\u001b[39mr2_score(test,preds)\n\u001b[0;32m     32\u001b[0m     mse \u001b[39m=\u001b[39m mean_squared_error(test,preds)\n\u001b[0;32m     33\u001b[0m     rmse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt(mean_squared_error(test,preds))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "Regression(df, 'FORCE_2020_LITHOFACIES_LITHOLOGY').LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class fit_model():\n",
    "\n",
    "        def __init__(self, data, column, OOT_shape = 20, datetime_column = None, cleaned=False):\n",
    "            if cleaned:\n",
    "                data = data[data['Switch']==1]\n",
    "                if data.shape[0]==0:\n",
    "                    print('No non-outlying data present.')\n",
    "                    return None\n",
    "                data = data.drop(['Comment', 'Switch'], axis = 1)\n",
    "            if datetime_column== None:\n",
    "                data = data.reset_index(drop=True).reset_index()\n",
    "                datetime_column= 'index'\n",
    "            self.datetime_column = datetime_column\n",
    "            self.target_column = column\n",
    "            data= data.dropna()\n",
    "            if data.shape[0] == 0:\n",
    "                raise NoDataPresentException\n",
    "            data = data.sort_values(by = self.datetime_column, ascending = True)\n",
    "            self.data_OOT = data.tail(OOT_shape)\n",
    "            data = data.drop(self.data_OOT.index)\n",
    "            self.y = data[column]\n",
    "            self.X = data.drop(column, axis = 1)\n",
    "            self.X_OOT = self.data_OOT.drop(column, axis = 1)\n",
    "            self.y_OOT = self.data_OOT[column]\n",
    "\n",
    "        def evaluate(self, test, preds, process='Train'):\n",
    "            score=r2_score(test,preds)\n",
    "            mse = mean_squared_error(test,preds)\n",
    "            rmse = np.sqrt(mean_squared_error(test,preds))\n",
    "            mape = mean_absolute_percentage_error(test,preds)\n",
    "\n",
    "            print('For {}'.format(process))\n",
    "            print('r2_score: {}\\nmse:{}\\nrmse:{}\\nmape:{}\\n'.format(score, mse, rmse, mape))\n",
    "\n",
    "            return score, mse, rmse, mape\n",
    "            \n",
    "            \n",
    "        def linear_regression(self, train_size = 0.8, random_state = 0, plot=True, **kwargs):\n",
    "            session = mlflow.start_run()\n",
    "            \n",
    "            with session : \n",
    "                \n",
    "                self.train_size = train_size       \n",
    "                self.random_state = random_state\n",
    "                \n",
    "                \n",
    "                self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size = train_size, random_state = random_state)\n",
    "                \n",
    "                self.x_test1 = self.x_test.drop(self.datetime_column, axis = 1)\n",
    "                self.x_train1 = self.x_train.drop(self.datetime_column, axis = 1) \n",
    "                \n",
    "                ## Building a model\n",
    "                self.model_type = 'LinearRegressor'       \n",
    "                self.model =  LinearRegression(**kwargs)\n",
    "                self.model.fit(self.x_train1,self.y_train)\n",
    "                \n",
    "                #Plotting feature importance\n",
    "                feat_importances = pd.Series(self.model.coef_, index=self.x_train1.columns)\n",
    "                feat_importances.nlargest(20).plot(kind='barh', figsize = (30, 30))\n",
    "                plt.show()\n",
    "                \n",
    "                ## On Training Data:\n",
    "                y_pred_train = self.model.predict(self.x_train1)\n",
    "                self.train_score, self.train_mse, self.train_rmse, self.train_mape = self.evaluate(self.y_train, y_pred_train, 'Train')\n",
    "                self.result_train = pd.DataFrame({'Actual': self.y_train, 'Predictions': y_pred_train, 'Date_time': self.x_train[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                ## On Testing Data:\n",
    "                y_pred_test = self.model.predict(self.x_test1)\n",
    "                self.test_score, self.test_mse, self.test_rmse, self.test_mape = self.evaluate(self.y_test, y_pred_test, 'Test')\n",
    "                self.result_test = pd.DataFrame({'Actual': self.y_test, 'Predictions': y_pred_test, 'Date_time': self.x_test[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "                ## On OOT data: \n",
    "                y_pred_OOT = self.model.predict(self.X_OOT.drop(self.datetime_column, axis = 1))\n",
    "                self.OOT_score, self.OOT_mse, self.OOT_rmse, self.OOT_mape = self.evaluate(self.y_OOT, y_pred_OOT, 'OOT')\n",
    "                self.result_OOT = pd.DataFrame({'Actual': self.y_OOT, 'Predictions': y_pred_OOT, 'Date_time': self.X_OOT[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                if plot:\n",
    "                    self.result_train.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_test.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_OOT.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    plt.show()\n",
    "\n",
    "                # Log parameters and metrics to MLflow\n",
    "                mlflow.log_param(\"train_size\", train_size)\n",
    "                mlflow.log_param(\"random_state\", random_state)\n",
    "                mlflow.log_param(\"model_type\", \"Linear Regressor\")\n",
    "                mlflow.log_params(kwargs)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_train\", self.train_score)\n",
    "                mlflow.log_metric(\"mse_train\", self.train_mse)\n",
    "                mlflow.log_metric(\"rmse_train\", self.train_rmse)\n",
    "                mlflow.log_metric(\"mape_train\", self.train_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_test\", self.test_score)\n",
    "                mlflow.log_metric(\"mse_test\", self.test_mse)\n",
    "                mlflow.log_metric(\"rmse_test\", self.test_rmse)\n",
    "                mlflow.log_metric(\"mape_test\", self.test_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_OOT\", self.OOT_score)\n",
    "                mlflow.log_metric(\"mse_OOT\", self.OOT_mse)\n",
    "                mlflow.log_metric(\"rmse_OOT\", self.OOT_rmse)\n",
    "                mlflow.log_metric(\"mape_OOT\", self.OOT_mape)\n",
    "\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n",
    "                \n",
    "                return self \n",
    "\n",
    "        def RandomForestRegressor(self, train_size = 0.8, random_state = 0, plot = True, **kwargs):\n",
    "            session = mlflow.start_run()\n",
    "            \n",
    "            with session : \n",
    "                \n",
    "                self.train_size = train_size       \n",
    "                self.random_state = random_state\n",
    "                \n",
    "                \n",
    "                self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size = train_size, random_state = random_state)\n",
    "                \n",
    "                self.x_test1 = self.x_test.drop(self.datetime_column, axis = 1)\n",
    "                self.x_train1 = self.x_train.drop(self.datetime_column, axis = 1) \n",
    "                \n",
    "                ## Building a model\n",
    "                self.model_type = 'RandomForestRegressor'       \n",
    "                self.model =  RandomForestRegressor(**kwargs)\n",
    "                self.model.fit(self.x_train1,self.y_train)\n",
    "                \n",
    "                #Plotting feature importance\n",
    "                feat_importances = pd.Series(self.model.feature_importances_, index=self.x_train1.columns)\n",
    "                feat_importances.nlargest(20).plot(kind='barh', figsize = (30, 30))\n",
    "                plt.show()\n",
    "                \n",
    "                ## On Training Data:\n",
    "                y_pred_train = self.model.predict(self.x_train1)\n",
    "                self.train_score, self.train_mse, self.train_rmse, self.train_mape = self.evaluate(self.y_train, y_pred_train, 'Train')\n",
    "                self.result_train = pd.DataFrame({'Actual': self.y_train, 'Predictions': y_pred_train, 'Date_time': self.x_train[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                ## On Testing Data:\n",
    "                y_pred_test = self.model.predict(self.x_test1)\n",
    "                self.test_score, self.test_mse, self.test_rmse, self.test_mape = self.evaluate(self.y_test, y_pred_test, 'Test')\n",
    "                self.result_test = pd.DataFrame({'Actual': self.y_test, 'Predictions': y_pred_test, 'Date_time': self.x_test[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "                ## On OOT data: \n",
    "                y_pred_OOT = self.model.predict(self.X_OOT.drop(self.datetime_column, axis = 1))\n",
    "                self.OOT_score, self.OOT_mse, self.OOT_rmse, self.OOT_mape = self.evaluate(self.y_OOT, y_pred_OOT, 'OOT')\n",
    "                self.result_OOT = pd.DataFrame({'Actual': self.y_OOT, 'Predictions': y_pred_OOT, 'Date_time': self.X_OOT[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                if plot:\n",
    "                    self.result_train.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_test.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_OOT.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    plt.show()\n",
    "\n",
    "                # Log parameters and metrics to MLflow\n",
    "                mlflow.log_param(\"train_size\", train_size)\n",
    "                mlflow.log_param(\"random_state\", random_state)\n",
    "                mlflow.log_param(\"model_type\", \"Random Forest Regressor\")\n",
    "                mlflow.log_params(kwargs)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_train\", self.train_score)\n",
    "                mlflow.log_metric(\"mse_train\", self.train_mse)\n",
    "                mlflow.log_metric(\"rmse_train\", self.train_rmse)\n",
    "                mlflow.log_metric(\"mape_train\", self.train_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_test\", self.test_score)\n",
    "                mlflow.log_metric(\"mse_test\", self.test_mse)\n",
    "                mlflow.log_metric(\"rmse_test\", self.test_rmse)\n",
    "                mlflow.log_metric(\"mape_test\", self.test_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_OOT\", self.OOT_score)\n",
    "                mlflow.log_metric(\"mse_OOT\", self.OOT_mse)\n",
    "                mlflow.log_metric(\"rmse_OOT\", self.OOT_rmse)\n",
    "                mlflow.log_metric(\"mape_OOT\", self.OOT_mape)\n",
    "\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n",
    "                \n",
    "                return self  \n",
    " \n",
    "        def XGBRegressor(self, train_size = 0.8, random_state = 0, plot = True, **kwargs):\n",
    "            session = mlflow.start_run()\n",
    "            \n",
    "            with session : \n",
    "                \n",
    "                self.train_size = train_size       \n",
    "                self.random_state = random_state\n",
    "                \n",
    "                \n",
    "                self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.X, self.y, train_size = train_size, random_state = random_state)\n",
    "                \n",
    "                self.x_test1 = self.x_test.drop(self.datetime_column, axis = 1)\n",
    "                self.x_train1 = self.x_train.drop(self.datetime_column, axis = 1) \n",
    "                \n",
    "                ## Building a model\n",
    "                self.model_type = 'XGBRegressor'       \n",
    "                self.model =  XGBRegressor(**kwargs)\n",
    "                self.model.fit(self.x_train1,self.y_train)\n",
    "                \n",
    "                #Plotting feature importance\n",
    "                feat_importances = pd.Series(self.model.feature_importances_, index=self.x_train1.columns)\n",
    "                feat_importances.nlargest(20).plot(kind='barh', figsize = (30, 30))\n",
    "                plt.show()\n",
    "                \n",
    "                ## On Training Data:\n",
    "                y_pred_train = self.model.predict(self.x_train1)\n",
    "                self.train_score, self.train_mse, self.train_rmse, self.train_mape = self.evaluate(self.y_train, y_pred_train, 'Train')\n",
    "                self.result_train = pd.DataFrame({'Actual': self.y_train, 'Predictions': y_pred_train, 'Date_time': self.x_train[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                ## On Testing Data:\n",
    "                y_pred_test = self.model.predict(self.x_test1)\n",
    "                self.test_score, self.test_mse, self.test_rmse, self.test_mape = self.evaluate(self.y_test, y_pred_test, 'Test')\n",
    "                self.result_test = pd.DataFrame({'Actual': self.y_test, 'Predictions': y_pred_test, 'Date_time': self.x_test[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "                ## On OOT data: \n",
    "                y_pred_OOT = self.model.predict(self.X_OOT.drop(self.datetime_column, axis = 1))\n",
    "                self.OOT_score, self.OOT_mse, self.OOT_rmse, self.OOT_mape = self.evaluate(self.y_OOT, y_pred_OOT, 'OOT')\n",
    "                self.result_OOT = pd.DataFrame({'Actual': self.y_OOT, 'Predictions': y_pred_OOT, 'Date_time': self.X_OOT[self.datetime_column]}).sort_values(by = 'Date_time', ascending=True).reset_index(drop = True)\n",
    "\n",
    "\n",
    "                if plot:\n",
    "                    self.result_train.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_test.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    self.result_OOT.plot(y=['Actual', 'Predictions'], x='Date_time', figsize = (30, 5))\n",
    "                    plt.show()\n",
    "\n",
    "                # Log parameters and metrics to MLflow\n",
    "                mlflow.log_param(\"train_size\", train_size)\n",
    "                mlflow.log_param(\"random_state\", random_state)\n",
    "                mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "                mlflow.log_params(kwargs)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_train\", self.train_score)\n",
    "                mlflow.log_metric(\"mse_train\", self.train_mse)\n",
    "                mlflow.log_metric(\"rmse_train\", self.train_rmse)\n",
    "                mlflow.log_metric(\"mape_train\", self.train_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_test\", self.test_score)\n",
    "                mlflow.log_metric(\"mse_test\", self.test_mse)\n",
    "                mlflow.log_metric(\"rmse_test\", self.test_rmse)\n",
    "                mlflow.log_metric(\"mape_test\", self.test_mape)\n",
    "\n",
    "                mlflow.log_metric(\"r2_score_OOT\", self.OOT_score)\n",
    "                mlflow.log_metric(\"mse_OOT\", self.OOT_mse)\n",
    "                mlflow.log_metric(\"rmse_OOT\", self.OOT_rmse)\n",
    "                mlflow.log_metric(\"mape_OOT\", self.OOT_mape)\n",
    "\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n",
    "                \n",
    "                return self  \n",
    "            \n",
    "        def PolynomialRegression(self, degree = 2, train_size = 0.8, random_state = 0, plot = True, **kwargs):\n",
    "            from sklearn.preprocessing import PolynomialFeatures  \n",
    "            from sklearn.model_selection import train_test_split  \n",
    "            from sklearn.linear_model import LinearRegression \n",
    "            from sklearn.metrics import r2_score  \n",
    "            from sklearn.metrics import mean_squared_error     \n",
    "            from sklearn.metrics import mean_absolute_percentage_error \n",
    "            with mlflow.start_run():\n",
    "                self.train_size = train_size    \n",
    "                self.random_state = random_state\n",
    "                self.model_type = 'PolynomialRegression' \n",
    "                x_train, x_test, y_train, y_test = train_test_split(self.X, self.y, train_size = train_size, random_state = random_state)\n",
    "                self.x_train = x_train    \n",
    "                self.x_test = x_test \n",
    "                self.y_train = y_train   \n",
    "                self.y_test = y_test   \n",
    "                print('Degree=',degree)\n",
    "                poly = PolynomialFeatures(degree = degree, include_bias = False)\n",
    "                x_train1 = poly.fit_transform(x_train)\n",
    "                self.model = LinearRegression()\n",
    "                self.model.fit(x_train1, y_train)\n",
    "                x_test1 = poly.fit_transform(x_test)\n",
    "                sc = self.model.score(x_test1, y_test)\n",
    "                y_prediction = self.model.predict(x_test1)\n",
    "                score=r2_score(y_test,y_prediction)\n",
    "                print('r2 socre is ',score)\n",
    "                print(\"Model Score: \", sc)\n",
    "                # Log parameters and metrics to MLflow\n",
    "                mlflow.log_param(\"train_size\", train_size)\n",
    "                mlflow.log_param(\"random_state\", random_state)\n",
    "                mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "                mlflow.log_params(kwargs)\n",
    "                mlflow.log_metric(\"r2_score\", score)\n",
    "                mlflow.log_metric(\"mse\", self.mse)\n",
    "                mlflow.log_metric(\"rmse\", self.rmse)\n",
    "                mlflow.log_metric(\"mape\", self.mape)\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n",
    "            return self \n",
    "        def tune_hyperparameters_XGBRegressor(self, n_estimators_range, max_depth_range, reg_lambda_range, eta_range, alpha_range, scoring = 'neg_mean_absolute_error', n_trials = 100, cv=5, plot=True):\n",
    "            def objective(trial):\n",
    "                n_estimators = trial.suggest_int('n_estimators', n_estimators_range[0], n_estimators_range[1])\n",
    "                max_depth = trial.suggest_int('max_depth', max_depth_range[0], max_depth_range[1])\n",
    "                reg_lambda = trial.suggest_loguniform('reg_lambda', reg_lambda_range[0], reg_lambda_range[1])\n",
    "                eta = trial.suggest_float(\"eta\", eta_range[0], eta_range[1])\n",
    "                alpha = trial.suggest_float(\"alpha\", alpha_range[0], alpha_range[1])\n",
    "                regressor = XGBRegressor(n_estimators = n_estimators, eta= eta, max_depth = max_depth, alpha = alpha, reg_lambda= reg_lambda)\n",
    "                return np.absolute(sklearn.model_selection.cross_val_score(regressor, self.X, self.y, scoring=scoring, n_jobs=-1, cv=cv)).mean()\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=n_trials)\n",
    "            trial = study.best_trial        \n",
    "            lg.info('Accuracy: {}'.format(trial.value))\n",
    "            lg.info(\"Best hyperparameters: {}\".format(trial.params))\n",
    "            optuna.visualization.plot_optimization_history(study)\n",
    "            self.model = XGBRegressor(n_estimators= trial.params['n_estimators'], eta= trial.params['eta'], max_depth= trial.params['max_depth'], alpha= trial.params['alpha'])\n",
    "            # Cross Validating the model        cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            scores = cross_val_score(self.model, self.X, self.y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "            scores = absolute(scores)\n",
    "            print('Displaying Cross Validation Scores.')\n",
    "            print('mean_MAE {}'.format(scores.mean()))\n",
    "            print('std_MAE: {}'.format(scores.std()))\n",
    "            self.model.fit(self.x_train, self.y_train)\n",
    "            y_prediction =  self.model.predict(self.x_test)\n",
    "            if plot:\n",
    "                result = pd.DataFrame({'Actual': self.y_test,\n",
    "                                    'Predictions': y_prediction})\n",
    "                result = result.reset_index(drop = True)\n",
    "                result.reset_index().plot(y=['Actual', 'Predictions'], figsize = (30, 5))\n",
    "                plt.show()\n",
    "            score=r2_score(self.y_test,y_prediction)\n",
    "            print('r2 socre is ',score)\n",
    "            self.r2_score = score       \n",
    "            print('mean_sqrd_error is==',mean_squared_error(self.y_test,y_prediction))\n",
    "            self.mse = mean_squared_error(self.y_test,y_prediction)\n",
    "            print('root_mean_squared error of is==',np.sqrt(mean_squared_error(self.y_test,y_prediction)))\n",
    "            self.rmse = np.sqrt(mean_squared_error(self.y_test,y_prediction))\n",
    "            print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(self.y_test,y_prediction))\n",
    "            self.mape = mean_absolute_percentage_error(self.y_test,y_prediction)\n",
    "            return self    \n",
    "        def tune_hyperparameters_RFRegressor(self, n_estimators_range, max_depth_range, scoring = 'neg_mean_absolute_error', n_trials = 100, cv= 3,plot=True):\n",
    "\n",
    "            def objective(trial):\n",
    "                n_estimators = trial.suggest_int('n_estimators', n_estimators_range[0], n_estimators_range[1])\n",
    "                max_depth = int(trial.suggest_loguniform('max_depth', max_depth_range[0], max_depth_range[1]))\n",
    "                regressor = RandomForestRegressor(n_estimators = n_estimators,  max_depth = max_depth)\n",
    "                return np.absolute(sklearn.model_selection.cross_val_score(regressor, self.X, self.y, scoring=scoring, n_jobs=-1, cv=cv)).mean()\n",
    "            # OPTUNA APPLICATION     \n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(objective, n_trials=100)\n",
    "            trial = study.best_trial   \n",
    "            lg.info('\\t\\tAccuracy: {}'.format(trial.value))\n",
    "            lg.info(\"\\t\\tBest hyperparameters: {}\".format(trial.params))\n",
    "            optuna.visualization.plot_optimization_history(study)\n",
    "            #Random Forest    \n",
    "            self.model = RandomForestRegressor(n_estimators=trial.params['n_estimators'], max_depth= trial.params['max_depth'])\n",
    "            # Cross Validating the model   \n",
    "            cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "            scores = cross_val_score(self.model, self.X, self.y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "            scores = absolute(scores)\n",
    "            print('Displaying Cross Validation Scores.')\n",
    "            print('mean_MAE {}'.format(scores.mean()))\n",
    "            print('std_MAE: {}'.format(scores.std()))\n",
    "            self.model.fit(self.x_train, self.y_train)\n",
    "            y_prediction =  self.model.predict(self.x_test)\n",
    "            if plot:\n",
    "                result = pd.DataFrame({'Actual': self.y_test,\n",
    "                                    'Predictions': y_prediction})\n",
    "                result.reset_index().plot(x = result.index, y=['Actual', 'Predictions'], figsize = (30, 5))\n",
    "                plt.show()\n",
    "            score=r2_score(self.y_test,y_prediction)\n",
    "            print('r2 socre is ',score)\n",
    "            self.r2_score = score       \n",
    "            print('mean_sqrd_error is==',mean_squared_error(self.y_test,y_prediction))\n",
    "            self.mse = mean_squared_error(self.y_test,y_prediction)\n",
    "            print('root_mean_squared error of is==',np.sqrt(mean_squared_error(self.y_test,y_prediction)))\n",
    "            self.rmse = np.sqrt(mean_squared_error(self.y_test,y_prediction))\n",
    "            print('Mean Absolute Percentage Error:', mean_absolute_percentage_error(self.y_test,y_prediction))\n",
    "            self.mape = mean_absolute_percentage_error(self.y_test,y_prediction)\n",
    "            return self   \n",
    "        def tune_hyperparameters_LinReg(self, ridge_alphas, ):\n",
    "            \n",
    "            #Applying Ridge Regression   \n",
    "            model1 =  RidgeCV(alphas=ridge_alphas).fit(self.X, self.y)\n",
    "            score1 = model1.score(self.X, self.y)\n",
    "\n",
    "\n",
    "        def apply_shap(self, feature_col_names, target_col_name):\n",
    "\n",
    "            data = pd.concat([self.X, self.y], axis = 1)\n",
    "            y, X = dmatrices( \"{}~ {} -1\".format(target_col_name, \" + \".join(feature_col_names)),\n",
    "                        data=data)\n",
    "            X_frame = pd.DataFrame(data=X, columns=X.design_info.column_names)\n",
    "\n",
    "            explainer = shap.Explainer(self.model)\n",
    "            shap_values = explainer(X_frame)\n",
    "            shap.plots.waterfall(shap_values[0])\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Regression-interactive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
